{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 (Part D) - Nonlinear regression\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "__IMPORTANT__ \n",
    "Please complete this Jupyter Notebook file and upload it to blackboard __before 05 February 2020__.\n",
    "</div>\n",
    "\n",
    "In this part, you will implement a nonlinear kernel regression. We will use the same house pricing dataset as previously. The following code simply loads the dataset from the data file into the variables $X$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization, always run this cell before anything else\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"datasets/ex1data2.txt\"\n",
    "mydata = np.genfromtxt(filename, delimiter=\",\")\n",
    "\n",
    "# We have n data-points\n",
    "n = len(mydata)\n",
    "\n",
    "# X is a matrix of two column, i.e. an array of n 2-dimensional data-points\n",
    "X = mydata[:, :2].reshape(n, 2)\n",
    "\n",
    "# y is the vector of outputs, i.e. an array of n scalar values\n",
    "y = mydata[:, -1]\n",
    "\n",
    "\"\"\" TODO:\n",
    "print a subset of X and y to see how it looks like\n",
    "\"\"\"\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to implement the *Nadaraya-Watson estimator*, which consists in a kernel regression using the *Gaussian kernel* function.\n",
    "\n",
    "The Gaussian kernel function of two vectors $v$ and $u$ is defined as $k(u, v) = e^{{-\\left \\| u - v \\right \\|}^2 ~/~ 2 \\sigma^2}$, where $\\sigma$ (sigma) is a hyperparameter representing the width of the Gaussian. The equation of the Gaussian kernel can be simplified to $k(u, v) = e^{{- \\gamma ~ \\left \\| u - v \\right \\|}^2}$ by considering a hyperparameter gamma: $\\gamma = \\frac{1}{\\sigma^2}$. Complete the code below to write the Gaussian kernel function `gaussian_kernel(..)` corresponding to $k(u, v) = e^{{- \\gamma ~ \\left \\| u - v \\right \\|}^2}$. You can use the Python function `math.exp(..)` to compute the exponancial, and `np.linalg.norm(u - v)` (or your own function) to compute the distance belween two vectors (numpy arrays) $u$ and $v$.\n",
    "\n",
    "The hypothesis function $h(x)$ to make a prediction about a new test data-point $x$ (i.e. predict the price of a new house), is defined as follows:\n",
    "$$h(x) = \\frac{1}{\\sum_{i=1}^n k(x, x^{(i)})} \\sum_{i=1}^n k(x, x^{(i)}) ~ y^{(i)},$$\n",
    "where $x$ is the test data-point, $x^{(i)}$ is the $i^{th}$ training data-point, and $y^{(i)}$ is the output (price) corresponding to the $i^{th}$ training data-point. Complete the code below to write `h(..)` the hypothesis function (which calls the `gaussian_kernel(..)` function).\n",
    "\n",
    "Once the hypothesis function `h(..)` is implemented, use it with $\\gamma = 0.00005$ to make a price prediction for a new house of 1650-square-foot with 3 bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" TODO: \n",
    "Write the definition of the gaussian_kernel(...) function. It takes as \n",
    "arguments two vectors u and v, and a hyperparameter gamma. This function \n",
    "can be considered as a measure of similarity between u and v.\n",
    "\"\"\"\n",
    "def gaussian_kernel(u, v, gamma):\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "\n",
    "\"\"\" TODO: \n",
    "Write the code for the hypothesis function h. The arguments are:\n",
    "*** x: one new test data-point\n",
    "*** X: the training data\n",
    "*** y: the training outputs\n",
    "*** gamma: the hyperparameter of the gaussian kernel\n",
    "Note: be careful about devisions by zero.\n",
    "\"\"\"\n",
    "def h(x, X, y, gamma):\n",
    "    # An array containing the similarity between x and all the others data-points in X :\n",
    "    similarities = np.array([ gaussian_kernel(x, xi, gamma) for xi in X ])\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Make a prediction for a new house x of 1650-square-foot with 3 bedrooms using gamma = 0.00005\n",
    "\"\"\"\n",
    "gamma = 0.00005\n",
    "x = np.array([1650, 3])\n",
    "# prediction = ...\n",
    "# print(\"The prediction on x is:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see that the hyperparameter $\\gamma$ affects the predicted output, you are asked to vary $\\gamma$ between $1e-10$ and $10e-5$ (you can use `np.arange(1e-10, 10e-5, 1e-5)` in Python), and see how the price predicted for the house `x = np.array([1650, 3])` varies with $\\gamma$. Do a plot of the $\\gamma$ values with respect to the price predicted for house `x`.\n",
    "\n",
    "**Note**: We will see later in the course how to automatically select a good value for hyperparameters such as $\\gamma$, using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "\"\"\" TODO:\n",
    "Complete the following code to predict the price of x based on different values of gamma\n",
    "\"\"\"\n",
    "\n",
    "x = np.array([1650, 3])\n",
    "gammas_list = np.arange(1e-10, 10e-5, 1e-5)\n",
    "predictions = []\n",
    "\n",
    "for gamma in gammas_list:\n",
    "    pass\n",
    "    # prediction = ... make a prediction on x using the current gamma ...\n",
    "    # append the prediction to the list of predictions\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# TODO: plot the values the predicted prices of x with respect to the corresponding values of gamma\n",
    "# ...\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split the training dataset into two parts. The first part `X_train` (and `y_train`) is used as a training data. The second part `X_test` is used to make price predictions and compare it to the true prices `y_test`.\n",
    "\n",
    "Complete the code to produce a list `y_pred` which contains the predicted price of each house in `X_test`. Then, produce a scatter plot based on `X_test`, `y_pred` and `y_test`, which shows the first feature (house size) on one axis vs. the predicted and true price on the other axis. The plot should look like the Figure below.\n",
    "\n",
    "Try several values of $\\gamma$ (e.g. $0.5, 0.00005, 0.00000001$) and see each time on the plot how your predicted prices change. Notice that when $\\gamma$ is smaller, the predicted values tend to be similar regradless of the test houses. Why ? Think about it before looking at the answer below.\n",
    "\n",
    "*Answer*: When $\\gamma$ is set to a very small value, the Gaussian width $\\sigma$ is very large. This makes all the values $\\{ k(x, x^{(i)}) \\mid i=1 \\dots n \\}$ large (close to 1), i.e., all the training data-points will equaly influence $h(x)$  (the predicted price of $x$). Therefore, the predicted price of any test point $x$ will just be the average price of all training houses.\n",
    "\n",
    "<img src=\"imgs/scatterLab2D.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma = 0.00005 # 0.5 0.00005, 0.00000001\n",
    "n = len(X)\n",
    "\n",
    "# The training part:\n",
    "X_train = X[ : n//2] # First half of the dataset\n",
    "y_train = y[ : n//2] # Outputs corresponding to the first half\n",
    "\n",
    "# The testing part:\n",
    "X_test = X[n//2 : ] # Second half of the dataset\n",
    "y_test = y[n//2 : ] # Outputs corresponding to the second half\n",
    "\n",
    "\n",
    "\"\"\" TODO: \n",
    "Based on X_train and y_train, predict the price of each house in X_test. \n",
    "These predictions will be in a list named y_pred.\n",
    "\"\"\"\n",
    "# y_pred = ...\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Complete the following code to produce a figure similar to the one shown above.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "# TODO: scatter plot of the first feature (column 0) of X_test vs. y_test\n",
    "# TODO: scatter plot of the first feature (column 0) of X_test vs. y_pred\n",
    "# ...\n",
    "# ...\n",
    "# ...\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
